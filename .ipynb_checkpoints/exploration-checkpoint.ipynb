{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from pyathena import connect\n",
    "from pyathena.common import BaseCursor\n",
    "from pyathena.pandas.cursor import PandasCursor\n",
    "from joblib import Parallel, delayed\n",
    "from plotly import graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from dataclasses import dataclass\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:85% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:85% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## rtscommons / constants.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_DAYS_BACK: int = 14\n",
    "DEFAULT_RISK: int = 10\n",
    "DEFAULT_SCORE_FUNCTION: str = \"risk\"\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class FeatureColumns:\n",
    "    bidder = \"bidder\"\n",
    "    hb_bidder_str = \"hb_bidder_str\"\n",
    "    network_id = \"networkId\"\n",
    "    slot_id = \"slotId\"\n",
    "    website_name = \"websiteName\"\n",
    "    yieldlove_no_adx = \"yieldlove_no_adx\"\n",
    "\n",
    "    gpp_estimated_win_rate = \"estimatedWinRate\"\n",
    "    kelvin_estimated_win_rate = \"kelvinEstimatedWinRate\"\n",
    "\n",
    "    auction_price = \"auctionPrice\"\n",
    "    price_bucket = \"pricebucket\"\n",
    "\n",
    "    @classmethod\n",
    "    def fetch_feature_columns(cls, model_name: str = \"GPP\") -> list:\n",
    "        return [\n",
    "            cls.bidder,\n",
    "            cls.gpp_estimated_win_rate if model_name == \"GPP\" else cls.kelvin_estimated_win_rate,\n",
    "            cls.hb_bidder_str,\n",
    "            cls.network_id,\n",
    "            cls.slot_id,\n",
    "            cls.yieldlove_no_adx,\n",
    "            cls.website_name,\n",
    "            cls.auction_price,\n",
    "            cls.price_bucket\n",
    "        ]\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class RtsColumns:\n",
    "    estimated_win_rate = \"estimated_win_rate\"\n",
    "\n",
    "    actual_win = \"actual_win\"\n",
    "    estimated_win = \"estimated_win\"\n",
    "\n",
    "    threshold = \"threshold\"\n",
    "    hour = \"hour_fixed\"\n",
    "    time_unit = \"time_unit\"\n",
    "    score = \"score\"\n",
    "    avg_cpm = \"avg_cpm\"\n",
    "    avg_pb = \"avg_pb\"\n",
    "\n",
    "    exclusion_percent = \"exclusion_percent\"\n",
    "    true_positive_percent = \"TP_percent\"\n",
    "    true_negative_percent = \"TN_percent\"\n",
    "    false_positive_percent = \"FP_percent\"\n",
    "    false_negative_percent = \"FN_percent\"\n",
    "\n",
    "    true_positive_rate = \"TPR\"\n",
    "    true_negative_rate = \"TNR\"\n",
    "    false_positive_rate = \"FPR\"\n",
    "    false_negative_rate = \"FNR\"\n",
    "    positive_predictive_value = \"PPV\"\n",
    "    negative_predictive_value = \"NPV\"\n",
    "    mcc = \"mcc\"\n",
    "    f1_score = \"f1_score\"\n",
    "\n",
    "    raw_true_positive = \"TP\"\n",
    "    raw_true_negative = \"TN\"\n",
    "    raw_false_positive = \"FP\"\n",
    "    raw_false_negative = \"FN\"\n",
    "    raw_exclusions = \"exclusions\"\n",
    "    raw_total = \"total_cases\"\n",
    "\n",
    "    @classmethod\n",
    "    def fetch_raw_number_columns(cls) -> list:\n",
    "        return [\n",
    "            cls.raw_true_positive,\n",
    "            cls.raw_true_negative,\n",
    "            cls.raw_false_positive,\n",
    "            cls.raw_false_negative,\n",
    "            cls.raw_exclusions,\n",
    "            cls.raw_total\n",
    "        ]\n",
    "\n",
    "    @classmethod\n",
    "    def fetch_display_columns(cls) -> list:\n",
    "        return [\n",
    "            cls.raw_true_positive,\n",
    "            cls.raw_true_negative,\n",
    "            cls.raw_false_positive,\n",
    "            cls.raw_false_negative,\n",
    "            cls.raw_exclusions,\n",
    "            cls.score\n",
    "        ]\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class BidderGroups:\n",
    "    invalid = [\n",
    "        \"A9\",\n",
    "        \"APIERROR\",\n",
    "        \"NO_META_KEY\",\n",
    "        \"RENDERED\",\n",
    "        \"UNKNOWN\",\n",
    "        \"UNFILLED\"\n",
    "    ]\n",
    "\n",
    "    google = [\n",
    "        \"ADX\",\n",
    "        \"BACKFILL\",\n",
    "        \"IO\",\n",
    "        \"IO-unknown\",\n",
    "        \"PASSBACK\",\n",
    "        \"SPONSORSHIP\"\n",
    "    ]\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class ThresholdSettings:\n",
    "    threshold_start = 0.01\n",
    "    threshold_stop = 0.99\n",
    "    threshold_step = 0.01\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class RiskSettings:\n",
    "    risk_start = 0.00\n",
    "    risk_stop = 1.00\n",
    "    risk_step = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## rtscommons / processing.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rate_as_percentage(numerator: int, denominator: int) -> float:\n",
    "    result = round(0.0, 2)\n",
    "    if denominator > 0:\n",
    "        result = round(100.0 * numerator / denominator, 2)\n",
    "    return result\n",
    "\n",
    "\n",
    "def determine_rates(df: pd.DataFrame, threshold: float, website: str, slot_id: int, risk_factor: float, score_function: str) -> dict:\n",
    "    df.reset_index(inplace=True)\n",
    "\n",
    "    TP = df[RtsColumns.raw_true_positive].iloc[0]\n",
    "    TN = df[RtsColumns.raw_true_negative].iloc[0]\n",
    "    FP = df[RtsColumns.raw_false_positive].iloc[0]\n",
    "    FN = df[RtsColumns.raw_false_negative].iloc[0]\n",
    "\n",
    "    total_estimated_wins = TP + FP\n",
    "    total_cases = TP + TN + FP + FN\n",
    "\n",
    "    result = dict()\n",
    "    result[RtsColumns.threshold] = round(threshold, 2)\n",
    "    result[FeatureColumns.website_name] = website\n",
    "    result[FeatureColumns.slot_id] = slot_id\n",
    "\n",
    "    # High level stats\n",
    "    result[RtsColumns.exclusion_percent] = get_rate_as_percentage(total_estimated_wins, total_cases)\n",
    "    result[RtsColumns.true_positive_percent] = get_rate_as_percentage(TP, total_cases)\n",
    "    result[RtsColumns.true_negative_percent] = get_rate_as_percentage(TN, total_cases)\n",
    "    result[RtsColumns.false_positive_percent] = get_rate_as_percentage(FP, total_cases)\n",
    "    result[RtsColumns.false_negative_percent] = get_rate_as_percentage(FN, total_cases)\n",
    "\n",
    "    # Low level stats\n",
    "    result[RtsColumns.true_positive_rate] = get_rate_as_percentage(TP, (TP + FN))\n",
    "    result[RtsColumns.true_negative_rate] = get_rate_as_percentage(TN, (TN + FP))\n",
    "    result[RtsColumns.false_positive_rate] = get_rate_as_percentage(FP, (FP + TN))\n",
    "    result[RtsColumns.false_negative_rate] = get_rate_as_percentage(FN, (FN + TP))\n",
    "    result[RtsColumns.positive_predictive_value] = get_rate_as_percentage(TP, (TP + FP))\n",
    "    result[RtsColumns.negative_predictive_value] = get_rate_as_percentage(TN, (TN + FN))\n",
    "\n",
    "    # Raw numbers\n",
    "    result[RtsColumns.raw_true_positive] = TP\n",
    "    result[RtsColumns.raw_true_negative] = TN\n",
    "    result[RtsColumns.raw_false_positive] = FP\n",
    "    result[RtsColumns.raw_false_negative] = FN\n",
    "    result[RtsColumns.raw_exclusions] = total_estimated_wins\n",
    "    result[RtsColumns.raw_total] = total_cases\n",
    "\n",
    "    # Score\n",
    "    result[RtsColumns.score] = min_max_score(result, risk_factor, score_function)\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def get_mcc_score(tp_percent: float, tn_percent: float, fp_percent: float, fn_percent: float) -> float:\n",
    "    numerator = (tp_percent * tn_percent) - (fp_percent * fn_percent)\n",
    "    denominator = math.sqrt((tp_percent + fp_percent) * (tp_percent + fn_percent) * (tn_percent + fp_percent) * (tn_percent + fn_percent))\n",
    "    result = 0.0\n",
    "    if denominator > 0:\n",
    "        result = round(numerator / denominator, 2)\n",
    "    return result\n",
    "\n",
    "\n",
    "def min_max_score(result: dict, risk_factor: float, score_function: str) -> float:\n",
    "    score = 0.0\n",
    "\n",
    "    tp_percent = result[RtsColumns.true_positive_percent]\n",
    "    tn_percent = result[RtsColumns.true_negative_percent]\n",
    "    fp_percent = result[RtsColumns.false_positive_percent]\n",
    "    fn_percent = result[RtsColumns.false_negative_percent]\n",
    "\n",
    "    if score_function == \"mcc\":\n",
    "        score = get_mcc_score(tp_percent, tn_percent, fp_percent, fn_percent)\n",
    "\n",
    "    elif score_function == \"risk\":\n",
    "        score = 100.0 - abs((100.0 * risk_factor) - result[RtsColumns.false_positive_rate])\n",
    "\n",
    "    elif score_function == \"class_imbalance\":\n",
    "        positive_predictive_value = result[RtsColumns.positive_predictive_value]\n",
    "        negative_predictive_value = result[RtsColumns.negative_predictive_value]\n",
    "        if tp_percent > 1.0:\n",
    "            # We want the smallest distance between these values, need to invert so that it is the highest score\n",
    "            score = 100.0 - abs(positive_predictive_value - negative_predictive_value)\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## rts / dataHandling.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_connection() -> BaseCursor:\n",
    "    return connect(\n",
    "        s3_staging_dir=\"s3://aws-athena-query-results-825119612905-eu-west-1/\",\n",
    "        region_name=\"eu-west-1\"\n",
    "    ).cursor(PandasCursor)\n",
    "\n",
    "\n",
    "def fetch_websites(day: str, model_name: str, cursor: BaseCursor) -> pd.DataFrame:\n",
    "    return cursor.execute(\n",
    "        operation=f\"\"\"\n",
    "        SELECT *\n",
    "        FROM (\n",
    "            SELECT \n",
    "                websiteName,\n",
    "                slotId,\n",
    "                ROUND(AVG(CASE WHEN yl2 = true THEN 1 ELSE 0 END), 2) as percent_ml_setup\n",
    "            FROM \"optimised\".\"yl_win\"\n",
    "            WHERE day >= CAST((date '{day}' - interval '1' day) as VARCHAR)\n",
    "            AND slotId is NOT null\n",
    "            AND '{\"estimatedWinRate\" if model_name == \"GPP\" else \"kelvinEstimatedWinRate\"}' is NOT null\n",
    "            AND websiteName is NOT null\n",
    "            GROUP BY websiteName, slotId\n",
    "            ORDER BY websiteName, slotId\n",
    "        )\n",
    "        WHERE percent_ml_setup >= 0.40\n",
    "        \"\"\"\n",
    "    ).as_pandas()\n",
    "\n",
    "\n",
    "def fetch_threshold_data(day: str, website: str, model_name: str, days_back: int, cursor: BaseCursor) -> pd.DataFrame:\n",
    "    return cursor.execute(\n",
    "        operation=f\"\"\"\n",
    "        SELECT \n",
    "            TP,\n",
    "            TN,\n",
    "            FP,\n",
    "            FN,\n",
    "            threshold,\n",
    "            slotId,\n",
    "            time_unit,\n",
    "            exclusions,\n",
    "            ml_app,\n",
    "            websiteName,\n",
    "            day\n",
    "        FROM \"optimised\".\"threshold_data\"\n",
    "        WHERE day >= CAST((date '{day}' - interval '{days_back}' day) as VARCHAR)\n",
    "        AND day <= '{day}'\n",
    "        AND websiteName = '{website}'\n",
    "        AND ml_app = '{model_name}'\n",
    "        \"\"\"\n",
    "    ).as_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_stats_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "\n",
    "    df_grouped = df.groupby([\"day\",  RtsColumns.time_unit, FeatureColumns.website_name, RtsColumns.threshold, \"ml_app\"]).sum().reset_index()\n",
    "\n",
    "    df_grouped[RtsColumns.raw_total] = df_grouped[RtsColumns.raw_true_positive] + df_grouped[RtsColumns.raw_true_negative] + df_grouped[RtsColumns.raw_false_positive] + df_grouped[RtsColumns.raw_false_negative]\n",
    "\n",
    "    df_grouped[RtsColumns.exclusion_percent] = 100.0 * df_grouped[RtsColumns.raw_exclusions] / df_grouped[RtsColumns.raw_total]\n",
    "    df_grouped[RtsColumns.exclusion_percent] = df_grouped[RtsColumns.exclusion_percent].astype(int)\n",
    "\n",
    "    # Percentages\n",
    "\n",
    "    df_grouped[RtsColumns.true_positive_percent] = 100.0 * df_grouped[RtsColumns.raw_true_positive] / df_grouped[RtsColumns.raw_total]\n",
    "    df_grouped[RtsColumns.true_positive_percent] = df_grouped[RtsColumns.true_positive_percent].astype(int)\n",
    "\n",
    "    df_grouped[RtsColumns.true_negative_percent] = 100.0 * df_grouped[RtsColumns.raw_true_negative] / df_grouped[RtsColumns.raw_total]\n",
    "    df_grouped[RtsColumns.true_negative_percent] = df_grouped[RtsColumns.true_negative_percent].astype(int)\n",
    "\n",
    "    df_grouped[RtsColumns.false_positive_percent] = 100.0 * df_grouped[RtsColumns.raw_false_positive] / df_grouped[RtsColumns.raw_total]\n",
    "    df_grouped[RtsColumns.false_positive_percent] = df_grouped[RtsColumns.false_positive_percent].astype(int)\n",
    "\n",
    "    df_grouped[RtsColumns.false_negative_percent] = 100.0 * df_grouped[RtsColumns.raw_false_negative] / df_grouped[RtsColumns.raw_total]\n",
    "    df_grouped[RtsColumns.false_negative_percent] = df_grouped[RtsColumns.false_negative_percent].astype(int)\n",
    "\n",
    "    # Rates\n",
    "\n",
    "    df_grouped[RtsColumns.true_positive_rate] = 100.0 * df_grouped[RtsColumns.raw_true_positive] / (df_grouped[RtsColumns.raw_true_positive] + df_grouped[RtsColumns.raw_false_negative])\n",
    "    df_grouped[RtsColumns.true_positive_rate] = df_grouped[RtsColumns.true_positive_rate].astype(int)\n",
    "\n",
    "    df_grouped[RtsColumns.true_negative_rate] = 100.0 * df_grouped[RtsColumns.raw_true_negative] / (df_grouped[RtsColumns.raw_true_negative] + df_grouped[RtsColumns.raw_false_positive])\n",
    "    df_grouped[RtsColumns.true_negative_rate] = df_grouped[RtsColumns.true_negative_rate].astype(int)\n",
    "\n",
    "    df_grouped[RtsColumns.false_positive_rate] = 100.0 * df_grouped[RtsColumns.raw_false_positive] / (df_grouped[RtsColumns.raw_false_positive] + df_grouped[RtsColumns.raw_true_negative])\n",
    "    df_grouped[RtsColumns.false_positive_rate] = df_grouped[RtsColumns.false_positive_rate].astype(int)\n",
    "\n",
    "    df_grouped[RtsColumns.false_negative_rate] = 100.0 * df_grouped[RtsColumns.raw_false_negative] / (df_grouped[RtsColumns.raw_false_negative] + df_grouped[RtsColumns.raw_true_positive])\n",
    "    df_grouped[RtsColumns.false_negative_rate] = df_grouped[RtsColumns.false_negative_rate].astype(int)\n",
    "\n",
    "    # PPV and NPV\n",
    "\n",
    "    df_grouped[RtsColumns.positive_predictive_value] = 100.0 * df_grouped[RtsColumns.raw_true_positive] / (df_grouped[RtsColumns.raw_true_positive] + df_grouped[RtsColumns.raw_false_positive])\n",
    "    df_grouped[RtsColumns.positive_predictive_value] = df_grouped[RtsColumns.positive_predictive_value].astype(int)\n",
    "\n",
    "    df_grouped[RtsColumns.negative_predictive_value] = 100.0 * df_grouped[RtsColumns.raw_true_negative] / (df_grouped[RtsColumns.raw_true_negative] + df_grouped[RtsColumns.raw_false_negative])\n",
    "    df_grouped[RtsColumns.negative_predictive_value] = df_grouped[RtsColumns.negative_predictive_value].astype(int)\n",
    "\n",
    "    return df_grouped\n",
    "\n",
    "\n",
    "def find_nearest_exclusion_rate(df: pd.DataFrame, exclusion_percent: int) -> pd.DataFrame:\n",
    "    dfs = []\n",
    "    for time_unit in sorted(df[RtsColumns.time_unit].unique()):\n",
    "        df_time = df.copy(deep=True)\n",
    "        df_time: pd.DataFrame = df_time.loc[df_time[RtsColumns.time_unit] == time_unit]\n",
    "        df_time[\"distance_to_exclusion_target\"] = df_time[RtsColumns.exclusion_percent] - exclusion_percent\n",
    "        df_time[\"distance_to_exclusion_target\"] = df_time[\"distance_to_exclusion_target\"].abs()\n",
    "        df_time.sort_values([\"distance_to_exclusion_target\"], ascending=True, inplace=True)\n",
    "        dfs.append(df_time[:1])\n",
    "    \n",
    "    return pd.concat(dfs)\n",
    "\n",
    "\n",
    "def generate_graph(df_demo: pd.DataFrame) -> pd.DataFrame:\n",
    "    columns_to_show = colour_map.keys()\n",
    "\n",
    "    fig = make_subplots(\n",
    "        y_title=\"Percentage\",\n",
    "        shared_xaxes=True\n",
    "    )\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=list(df_demo[RtsColumns.time_unit]),\n",
    "            y=list(df_demo[RtsColumns.threshold]),\n",
    "            name=RtsColumns.threshold,\n",
    "            line={\"color\": \"blue\", \"width\": 3}\n",
    "        )\n",
    "    )\n",
    "\n",
    "    for column in columns_to_show:\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=df_demo[RtsColumns.time_unit],\n",
    "                y=df_demo[column],\n",
    "                name=column,\n",
    "                line={\"color\": colour_map[column], \"width\": 4}\n",
    "            )\n",
    "        )\n",
    "\n",
    "    fig.update_layout(\n",
    "        autosize=True,\n",
    "        hovermode=\"x\",\n",
    "        yaxis_range=[0, 100]\n",
    "    )\n",
    "    \n",
    "    return fig\n",
    "\n",
    "\n",
    "def generate_arima_forecast(df: pd.DataFrame, column: str) -> int:\n",
    "    model = ARIMA(df[column].values, order=(1, 0, 0), seasonal_order=(1, 0, 1, 24))\n",
    "    model_fit = model.fit()\n",
    "    return int(model_fit.forecast()[0])\n",
    "\n",
    "\n",
    "def generate_arima_score(df: pd.DataFrame, seasonality: int) -> float:\n",
    "    print(f\"Trying ARIMA with seasonality {seasonality}\")\n",
    "    \n",
    "    series = df[\"threshold\"]\n",
    "\n",
    "    # split into train and test sets\n",
    "    X = series.values\n",
    "    total_values = len(X)\n",
    "\n",
    "    train = X[:int(total_values * 0.6)]\n",
    "    valid = X[int(total_values * 0.6):int(total_values * 0.8)]\n",
    "    test = X[int(total_values * 0.8):]\n",
    "\n",
    "    history = [x for x in train]\n",
    "    predictions = [0 for x in train]\n",
    "\n",
    "    valid_hist = []\n",
    "    valid_pred = []\n",
    "    for t in tqdm(range(len(valid))):\n",
    "        model = ARIMA(history, order=(1,0,0), seasonal_order=(1, 0, 1, seasonality))\n",
    "        model_fit = model.fit()\n",
    "        output = model_fit.forecast()\n",
    "        yhat = output[0]\n",
    "        predictions.append(yhat)\n",
    "        obs = valid[t]\n",
    "        history.append(obs)\n",
    "        valid_hist.append(obs)\n",
    "        valid_pred.append(yhat)\n",
    "\n",
    "    future_predictions = model_fit.predict(int(total_values * 0.8), total_values)\n",
    "    for t in range(len(test)):\n",
    "        yhat = future_predictions[t]\n",
    "        predictions.append(yhat)\n",
    "        obs = test[t]\n",
    "        history.append(obs)\n",
    "    \n",
    "    return r2_score(valid_hist, valid_pred)\n",
    "\n",
    "\n",
    "def generate_evaluation(df: pd.DataFrame) -> dict:\n",
    "    print(f\"Generating evaluations\")\n",
    "    arima_score_08 = generate_arima_score(df, 8)\n",
    "    arima_score_16 = generate_arima_score(df, 16)\n",
    "    arima_score_24 = generate_arima_score(df, 24)\n",
    "    \n",
    "    # Evaluations\n",
    "    total_values = df.shape[0]\n",
    "    df[\"ema_02\"] = round(df[\"threshold\"].ewm(span=2).mean(), 2)\n",
    "    df[\"sma_02\"] = round(df[\"threshold\"].rolling(2).mean())\n",
    "    df[\"ema_04\"] = round(df[\"threshold\"].ewm(span=4).mean(), 2)\n",
    "    df[\"sma_04\"] = round(df[\"threshold\"].rolling(4).mean(), 2)\n",
    "\n",
    "    return {\n",
    "        \"score_arima_08\": arima_score_08,\n",
    "        \"score_arima_16\": arima_score_16,\n",
    "        \"score_arima_24\": arima_score_24,\n",
    "        \"score_ema_02\" : r2_score(list(df[\"threshold\"].shift(-1).iloc[int(total_values*0.6):int(total_values*0.8)].values), list(df[\"ema_02\"].iloc[int(total_values*0.6):int(total_values*0.8)].values)),\n",
    "        \"score_ema_04\" : r2_score(list(df[\"threshold\"].shift(-1).iloc[int(total_values*0.6):int(total_values*0.8)].values), list(df[\"ema_04\"].iloc[int(total_values*0.6):int(total_values*0.8)].values)),\n",
    "        \"score_sma_02\" : r2_score(list(df[\"threshold\"].shift(-1).iloc[int(total_values*0.6):int(total_values*0.8)].values), list(df[\"sma_02\"].iloc[int(total_values*0.6):int(total_values*0.8)].values)),\n",
    "        \"score_sma_04\" : r2_score(list(df[\"threshold\"].shift(-1).iloc[int(total_values*0.6):int(total_values*0.8)].values), list(df[\"sma_04\"].iloc[int(total_values*0.6):int(total_values*0.8)].values)),\n",
    "        \"score_last_threshold\" : r2_score(list(df[\"threshold\"].shift(-1).iloc[int(total_values*0.6):int(total_values*0.8)].values), list(df[\"threshold\"].iloc[int(total_values*0.6):int(total_values*0.8)].values))\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "day = \"2021-03-04\"\n",
    "days_back = 14\n",
    "\n",
    "model_name = \"KMT\"\n",
    "\n",
    "colour_map = {\n",
    "    RtsColumns.threshold: \"gray\",\n",
    "    RtsColumns.exclusion_percent: \"black\",\n",
    "    RtsColumns.true_positive_percent: \"green\",\n",
    "    RtsColumns.true_negative_percent: \"blue\",\n",
    "    RtsColumns.false_positive_percent: \"red\",\n",
    "    RtsColumns.false_negative_percent: \"sandybrown\",\n",
    "    RtsColumns.positive_predictive_value: \"olivedrab\",\n",
    "    RtsColumns.negative_predictive_value: \"magenta\",\n",
    "    RtsColumns.true_positive_rate: \"forestgreen\",\n",
    "    RtsColumns.true_negative_rate: \"darkturquoise\",\n",
    "    RtsColumns.false_positive_rate: \"maroon\",\n",
    "    RtsColumns.false_negative_rate: \"darkkhaki\"\n",
    "}\n",
    "\n",
    "websites_to_explore = [\n",
    "    \"lecker.de_m\", \n",
    "    \"lecker.de_d\",\n",
    "    \"4players.de_m\",\n",
    "    \"4players.de_d\",\n",
    "    \"kicker.de_m\",\n",
    "    \"kicker.de_d\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3ce5f71fa7f4a198199957a9f2380d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=6.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Website = lecker.de_m\n",
      "Generating evaluations\n",
      "Trying ARIMA with seasonality 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a00a13acb85e4c23b27cfb5b5eb9ecf2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=72.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Trying ARIMA with seasonality 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a1360cbf86e4a569060f91ff3d15958",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=72.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Trying ARIMA with seasonality 24\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b167a38ca5a45c68a20f5f97f549dfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=72.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99eb88d777c94218bdd063b17a8ec4c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=12.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Field - threshold forecasts to - 65\n",
      "Field - exclusion_percent forecasts to - 40\n",
      "Field - TP_percent forecasts to - 24\n",
      "Field - TN_percent forecasts to - 44\n",
      "Field - FP_percent forecasts to - 15\n",
      "Field - FN_percent forecasts to - 13\n",
      "Field - PPV forecasts to - 60\n",
      "Field - NPV forecasts to - 75\n",
      "Field - TPR forecasts to - 62\n",
      "Field - TNR forecasts to - 73\n",
      "Field - FPR forecasts to - 25\n",
      "Field - FNR forecasts to - 36\n",
      "\n",
      "\n",
      "Website = lecker.de_d\n",
      "Generating evaluations\n",
      "Trying ARIMA with seasonality 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "990e3f7fbb76453e927db78ac7b5b6d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=72.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Trying ARIMA with seasonality 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2eea7e5403ea4bd9b910043a566d56da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=72.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Trying ARIMA with seasonality 24\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cccbb42a36a4486ab46dd40431eaaf0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=72.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd590c8363004078b6baaf6e0a260f2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=12.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Field - threshold forecasts to - 64\n",
      "Field - exclusion_percent forecasts to - 40\n",
      "Field - TP_percent forecasts to - 11\n",
      "Field - TN_percent forecasts to - 46\n",
      "Field - FP_percent forecasts to - 27\n",
      "Field - FN_percent forecasts to - 11\n",
      "Field - PPV forecasts to - 31\n",
      "Field - NPV forecasts to - 78\n",
      "Field - TPR forecasts to - 50\n",
      "Field - TNR forecasts to - 62\n",
      "Field - FPR forecasts to - 36\n",
      "Field - FNR forecasts to - 47\n",
      "\n",
      "\n",
      "Website = 4players.de_m\n",
      "Generating evaluations\n",
      "Trying ARIMA with seasonality 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ec418901d854e17b47aab7758e4ee00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=72.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Trying ARIMA with seasonality 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8e227871fca42cba305325c3a691a12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=72.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Trying ARIMA with seasonality 24\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b37610a7d51e46689c572a4f1d97097e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=72.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "929d04d7dbcf4f43885d749efc4cb062",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=12.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Field - threshold forecasts to - 55\n",
      "Field - exclusion_percent forecasts to - 40\n",
      "Field - TP_percent forecasts to - 23\n",
      "Field - TN_percent forecasts to - 45\n",
      "Field - FP_percent forecasts to - 15\n",
      "Field - FN_percent forecasts to - 13\n",
      "Field - PPV forecasts to - 58\n",
      "Field - NPV forecasts to - 76\n",
      "Field - TPR forecasts to - 62\n",
      "Field - TNR forecasts to - 72\n",
      "Field - FPR forecasts to - 26\n",
      "Field - FNR forecasts to - 36\n",
      "\n",
      "\n",
      "Website = 4players.de_d\n",
      "Generating evaluations\n",
      "Trying ARIMA with seasonality 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4050083c3e294b599c1d81d745832e41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=72.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Trying ARIMA with seasonality 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c381e72bfcd44ea89e9da9bf0a82490",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=72.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Trying ARIMA with seasonality 24\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d864c0f59ad94137b7bb4f77461005aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=72.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-8e66777c7113>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mdf_demo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_nearest_exclusion_rate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_grouped\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexclusion_percent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mwebsite_evaluations\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mwebsite_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_evaluation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_demo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0marima_outcome\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-513e0ac25cff>\u001b[0m in \u001b[0;36mgenerate_evaluation\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0marima_score_08\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_arima_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m     \u001b[0marima_score_16\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_arima_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m     \u001b[0marima_score_24\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_arima_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m24\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;31m# Evaluations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-513e0ac25cff>\u001b[0m in \u001b[0;36mgenerate_arima_score\u001b[0;34m(df, seasonality)\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mARIMA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseasonal_order\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseasonality\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m         \u001b[0mmodel_fit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_fit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforecast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0myhat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.3/envs/scratch/lib/python3.8/site-packages/statsmodels/tsa/arima/model.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, start_params, transformed, includes_fixed, method, method_kwargs, gls, gls_kwargs, cov_type, cov_kwds, return_params, low_memory)\u001b[0m\n\u001b[1;32m    341\u001b[0m                 \u001b[0mmethod_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'disp'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 343\u001b[0;31m                 res = super(ARIMA, self).fit(\n\u001b[0m\u001b[1;32m    344\u001b[0m                     \u001b[0mreturn_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlow_memory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlow_memory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m                     cov_type=cov_type, cov_kwds=cov_kwds, **method_kwargs)\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.3/envs/scratch/lib/python3.8/site-packages/statsmodels/tsa/statespace/mlemodel.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, start_params, transformed, includes_fixed, cov_type, cov_kwds, method, maxiter, full_output, disp, callback, return_params, optim_score, optim_complex_step, optim_hessian, flags, low_memory, **kwargs)\u001b[0m\n\u001b[1;32m    688\u001b[0m                 \u001b[0mflags\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'hessian_method'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim_hessian\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    689\u001b[0m             \u001b[0mfargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 690\u001b[0;31m             mlefit = super(MLEModel, self).fit(start_params, method=method,\n\u001b[0m\u001b[1;32m    691\u001b[0m                                                \u001b[0mfargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m                                                \u001b[0mmaxiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaxiter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.3/envs/scratch/lib/python3.8/site-packages/statsmodels/base/model.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, start_params, method, maxiter, full_output, disp, fargs, callback, retall, skip_hessian, **kwargs)\u001b[0m\n\u001b[1;32m    517\u001b[0m         \u001b[0mwarn_convergence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'warn_convergence'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m         \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOptimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 519\u001b[0;31m         xopt, retvals, optim_settings = optimizer._fit(f, score, start_params,\n\u001b[0m\u001b[1;32m    520\u001b[0m                                                        \u001b[0mfargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m                                                        \u001b[0mhessian\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhess\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.3/envs/scratch/lib/python3.8/site-packages/statsmodels/base/optimizer.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, objective, gradient, start_params, fargs, kwargs, hessian, method, maxiter, full_output, disp, callback, retall)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_funcs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         xopt, retvals = func(objective, gradient, start_params, fargs, kwargs,\n\u001b[0m\u001b[1;32m    225\u001b[0m                             \u001b[0mdisp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdisp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaxiter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m                             \u001b[0mretall\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfull_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.3/envs/scratch/lib/python3.8/site-packages/statsmodels/base/optimizer.py\u001b[0m in \u001b[0;36m_fit_lbfgs\u001b[0;34m(f, score, start_params, fargs, kwargs, disp, maxiter, callback, retall, full_output, hess)\u001b[0m\n\u001b[1;32m    627\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 629\u001b[0;31m     retvals = optimize.fmin_l_bfgs_b(func, start_params, maxiter=maxiter,\n\u001b[0m\u001b[1;32m    630\u001b[0m                                      \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m                                      \u001b[0mbounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbounds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdisp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.3/envs/scratch/lib/python3.8/site-packages/scipy/optimize/lbfgsb.py\u001b[0m in \u001b[0;36mfmin_l_bfgs_b\u001b[0;34m(func, x0, fprime, args, approx_grad, bounds, m, factr, pgtol, epsilon, iprint, maxfun, maxiter, disp, callback, maxls)\u001b[0m\n\u001b[1;32m    195\u001b[0m             'maxls': maxls}\n\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m     res = _minimize_lbfgsb(fun, x0, args=args, jac=jac, bounds=bounds,\n\u001b[0m\u001b[1;32m    198\u001b[0m                            **opts)\n\u001b[1;32m    199\u001b[0m     d = {'grad': res['jac'],\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.3/envs/scratch/lib/python3.8/site-packages/scipy/optimize/lbfgsb.py\u001b[0m in \u001b[0;36m_minimize_lbfgsb\u001b[0;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[1;32m    358\u001b[0m             \u001b[0;31m# until the completion of the current minimization iteration.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0;31m# Overwrite f and g:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 360\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    361\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtask_str\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb'NEW_X'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m             \u001b[0;31m# new iteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.3/envs/scratch/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py\u001b[0m in \u001b[0;36mfun_and_grad\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    199\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_x_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.3/envs/scratch/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py\u001b[0m in \u001b[0;36m_update_grad\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_update_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg_updated\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_grad_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg_updated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.3/envs/scratch/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py\u001b[0m in \u001b[0;36mupdate_grad\u001b[0;34m()\u001b[0m\n\u001b[1;32m     89\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mngev\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m                 self.g = approx_derivative(fun_wrapped, self.x, f0=self.f,\n\u001b[0m\u001b[1;32m     92\u001b[0m                                            **finite_diff_options)\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.3/envs/scratch/lib/python3.8/site-packages/scipy/optimize/_numdiff.py\u001b[0m in \u001b[0;36mapprox_derivative\u001b[0;34m(fun, x0, method, rel_step, abs_step, f0, bounds, sparsity, as_linear_operator, args, kwargs)\u001b[0m\n\u001b[1;32m    424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msparsity\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 426\u001b[0;31m             return _dense_difference(fun_wrapped, x0, f0, h,\n\u001b[0m\u001b[1;32m    427\u001b[0m                                      use_one_sided, method)\n\u001b[1;32m    428\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.3/envs/scratch/lib/python3.8/site-packages/scipy/optimize/_numdiff.py\u001b[0m in \u001b[0;36m_dense_difference\u001b[0;34m(fun, x0, f0, h, use_one_sided, method)\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx0\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mh_vecs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m             \u001b[0mdx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mx0\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Recompute dx as exactly representable number.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 497\u001b[0;31m             \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mf0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    498\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'3-point'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0muse_one_sided\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m             \u001b[0mx1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx0\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mh_vecs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.3/envs/scratch/lib/python3.8/site-packages/scipy/optimize/_numdiff.py\u001b[0m in \u001b[0;36mfun_wrapped\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfun_wrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0matleast_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m             raise RuntimeError(\"`fun` return value has \"\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.3/envs/scratch/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py\u001b[0m in \u001b[0;36mfun_wrapped\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mfun_wrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnfev\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.3/envs/scratch/lib/python3.8/site-packages/statsmodels/base/model.py\u001b[0m in \u001b[0;36mf\u001b[0;34m(params, *args)\u001b[0m\n\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloglike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnobs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    502\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'newton'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.3/envs/scratch/lib/python3.8/site-packages/statsmodels/tsa/statespace/mlemodel.py\u001b[0m in \u001b[0;36mloglike\u001b[0;34m(self, params, *args, **kwargs)\u001b[0m\n\u001b[1;32m    923\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'inversion_method'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mINVERT_UNIVARIATE\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mSOLVE_LU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    924\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 925\u001b[0;31m         \u001b[0mloglike\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mssm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloglike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomplex_step\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcomplex_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    926\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    927\u001b[0m         \u001b[0;31m# Koopman, Shephard, and Doornik recommend maximizing the average\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.3/envs/scratch/lib/python3.8/site-packages/statsmodels/tsa/statespace/kalman_filter.py\u001b[0m in \u001b[0;36mloglike\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    981\u001b[0m         kwargs.setdefault('conserve_memory',\n\u001b[1;32m    982\u001b[0m                           MEMORY_CONSERVE ^ MEMORY_NO_LIKELIHOOD)\n\u001b[0;32m--> 983\u001b[0;31m         \u001b[0mkfilter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    984\u001b[0m         loglikelihood_burn = kwargs.get('loglikelihood_burn',\n\u001b[1;32m    985\u001b[0m                                         self.loglikelihood_burn)\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.3/envs/scratch/lib/python3.8/site-packages/statsmodels/tsa/statespace/kalman_filter.py\u001b[0m in \u001b[0;36m_filter\u001b[0;34m(self, filter_method, inversion_method, stability_method, conserve_memory, filter_timing, tolerance, loglikelihood_burn, complex_step)\u001b[0m\n\u001b[1;32m    901\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0;31m# Initialize the state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 903\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomplex_step\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcomplex_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    904\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    905\u001b[0m         \u001b[0;31m# Run the filter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.3/envs/scratch/lib/python3.8/site-packages/statsmodels/tsa/statespace/representation.py\u001b[0m in \u001b[0;36m_initialize_state\u001b[0;34m(self, prefix, complex_step)\u001b[0m\n\u001b[1;32m    983\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialization\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialized\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Initialization is incomplete.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 985\u001b[0;31m             self._statespaces[prefix].initialize(self.initialization,\n\u001b[0m\u001b[1;32m    986\u001b[0m                                                  complex_step=complex_step)\n\u001b[1;32m    987\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "figures = dict()\n",
    "arima_outcomes = dict()\n",
    "website_evaluations = dict()\n",
    "\n",
    "for website_name in tqdm(websites_to_explore):\n",
    "    print(f\"Website = {website_name}\")\n",
    "\n",
    "    df = fetch_threshold_data(\n",
    "        day=day, \n",
    "        website=website_name, \n",
    "        model_name=model_name, \n",
    "        days_back=days_back, \n",
    "        cursor=get_connection()\n",
    "    )\n",
    "    \n",
    "    df[RtsColumns.threshold] = df[RtsColumns.threshold] * 100.0\n",
    "    df_grouped = generate_stats_columns(df=df)\n",
    "    df_demo = find_nearest_exclusion_rate(df=df_grouped, exclusion_percent=40)\n",
    "    \n",
    "    website_evaluations[website_name] = generate_evaluation(df_demo)\n",
    "    \n",
    "    arima_outcome = dict()\n",
    "    for column in tqdm(colour_map.keys()):\n",
    "        field_forecast = generate_arima_forecast(df_demo, column)\n",
    "        arima_outcome[column] = field_forecast\n",
    "        print(f\"Field - {column} forecasts to - {field_forecast}\")\n",
    "    \n",
    "    print()\n",
    "    arima_outcomes[website_name] = arima_outcome\n",
    "    figures[website_name] = generate_graph(df_demo=df_demo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_scores = []\n",
    "\n",
    "for website in website_evaluations:\n",
    "    print(f\"\\n{website}\")\n",
    "    website_eval = website_evaluations[website]\n",
    "    \n",
    "    keys = []\n",
    "    scores = []\n",
    "    for key in website_eval.keys():\n",
    "        if key not in [\"model_fit\", \"fig\"]:\n",
    "            keys.append(key)\n",
    "            score = round(website_eval[key], 2)\n",
    "            scores.append(score)\n",
    "            print(f\"{key} = {score}\")\n",
    "    \n",
    "    all_scores.append(scores)\n",
    "    \n",
    "fig = go.Figure(data=go.Heatmap(\n",
    "    z=all_scores,\n",
    "    x=keys,\n",
    "    y=list(website_evaluations.keys())\n",
    "))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.write_html(\"/home/tomm/Downloads/forecastComparison.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2f9e2b4d2ca4d47b19857395a530486",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=6.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Website = lecker.de_m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c02351a8b3b748daa5ea2cb69805c75b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=12.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Field - threshold forecasts to - 65\n",
      "Field - exclusion_percent forecasts to - 40\n",
      "Field - TP_percent forecasts to - 24\n",
      "Field - TN_percent forecasts to - 44\n",
      "Field - FP_percent forecasts to - 15\n",
      "Field - FN_percent forecasts to - 13\n",
      "Field - PPV forecasts to - 60\n",
      "Field - NPV forecasts to - 75\n",
      "Field - TPR forecasts to - 62\n",
      "Field - TNR forecasts to - 73\n",
      "Field - FPR forecasts to - 25\n",
      "Field - FNR forecasts to - 36\n",
      "\n",
      "\n",
      "Website = lecker.de_d\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b01fa61218a84a809a1952000e614a56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=12.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Field - threshold forecasts to - 64\n",
      "Field - exclusion_percent forecasts to - 40\n",
      "Field - TP_percent forecasts to - 11\n",
      "Field - TN_percent forecasts to - 46\n",
      "Field - FP_percent forecasts to - 27\n",
      "Field - FN_percent forecasts to - 11\n",
      "Field - PPV forecasts to - 31\n",
      "Field - NPV forecasts to - 78\n",
      "Field - TPR forecasts to - 50\n",
      "Field - TNR forecasts to - 62\n",
      "Field - FPR forecasts to - 36\n",
      "Field - FNR forecasts to - 47\n",
      "\n",
      "\n",
      "Website = 4players.de_m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d22d01ba6d58437e8e35d12be90f215c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=12.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Field - threshold forecasts to - 55\n",
      "Field - exclusion_percent forecasts to - 40\n",
      "Field - TP_percent forecasts to - 23\n",
      "Field - TN_percent forecasts to - 45\n",
      "Field - FP_percent forecasts to - 15\n",
      "Field - FN_percent forecasts to - 13\n",
      "Field - PPV forecasts to - 58\n",
      "Field - NPV forecasts to - 76\n",
      "Field - TPR forecasts to - 62\n",
      "Field - TNR forecasts to - 72\n",
      "Field - FPR forecasts to - 26\n",
      "Field - FNR forecasts to - 36\n",
      "\n",
      "\n",
      "Website = 4players.de_d\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a572959e82924d4e92aabd44baf3f088",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=12.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Field - threshold forecasts to - 61\n",
      "Field - exclusion_percent forecasts to - 39\n",
      "Field - TP_percent forecasts to - 18\n",
      "Field - TN_percent forecasts to - 42\n",
      "Field - FP_percent forecasts to - 20\n",
      "Field - FN_percent forecasts to - 15\n",
      "Field - PPV forecasts to - 46\n",
      "Field - NPV forecasts to - 72\n",
      "Field - TPR forecasts to - 55\n",
      "Field - TNR forecasts to - 66\n",
      "Field - FPR forecasts to - 32\n",
      "Field - FNR forecasts to - 43\n",
      "\n",
      "\n",
      "Website = kicker.de_m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "803f8e46cc06477c884473e352edccca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=12.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Field - threshold forecasts to - 76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tomm/.pyenv/versions/3.8.3/envs/scratch/lib/python3.8/site-packages/statsmodels/base/model.py:566: ConvergenceWarning:\n",
      "\n",
      "Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Field - exclusion_percent forecasts to - 39\n",
      "Field - TP_percent forecasts to - 29\n",
      "Field - TN_percent forecasts to - 30\n",
      "Field - FP_percent forecasts to - 10\n",
      "Field - FN_percent forecasts to - 27\n",
      "Field - PPV forecasts to - 72\n",
      "Field - NPV forecasts to - 51\n",
      "Field - TPR forecasts to - 50\n",
      "Field - TNR forecasts to - 73\n",
      "Field - FPR forecasts to - 25\n",
      "Field - FNR forecasts to - 48\n",
      "\n",
      "\n",
      "Website = kicker.de_d\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08bf9a5e58e74add85494e45ede8ea76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=12.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Field - threshold forecasts to - 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tomm/.pyenv/versions/3.8.3/envs/scratch/lib/python3.8/site-packages/statsmodels/base/model.py:566: ConvergenceWarning:\n",
      "\n",
      "Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Field - exclusion_percent forecasts to - 40\n",
      "Field - TP_percent forecasts to - 16\n",
      "Field - TN_percent forecasts to - 45\n",
      "Field - FP_percent forecasts to - 24\n",
      "Field - FN_percent forecasts to - 12\n",
      "Field - PPV forecasts to - 39\n",
      "Field - NPV forecasts to - 78\n",
      "Field - TPR forecasts to - 54\n",
      "Field - TNR forecasts to - 64\n",
      "Field - FPR forecasts to - 34\n",
      "Field - FNR forecasts to - 44\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "figures = dict()\n",
    "arima_outcomes = dict()\n",
    "website_evaluations = dict()\n",
    "\n",
    "for website_name in tqdm(websites_to_explore):\n",
    "    print(f\"Website = {website_name}\")\n",
    "\n",
    "    df = fetch_threshold_data(\n",
    "        day=day, \n",
    "        website=website_name, \n",
    "        model_name=model_name, \n",
    "        days_back=days_back, \n",
    "        cursor=get_connection()\n",
    "    )\n",
    "    \n",
    "    df[RtsColumns.threshold] = df[RtsColumns.threshold] * 100.0\n",
    "    df_grouped = generate_stats_columns(df=df)\n",
    "    df_demo = find_nearest_exclusion_rate(df=df_grouped, exclusion_percent=40)\n",
    "    \n",
    "    arima_outcome = dict()\n",
    "    for column in tqdm(colour_map.keys()):\n",
    "        field_forecast = generate_arima_forecast(df_demo, column)\n",
    "        arima_outcome[column] = field_forecast\n",
    "        print(f\"Field - {column} forecasts to - {field_forecast}\")\n",
    "    \n",
    "    print()\n",
    "    arima_outcomes[website_name] = arima_outcome\n",
    "    figures[website_name] = generate_graph(df_demo=df_demo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
